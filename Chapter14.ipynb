{
 "metadata": {
  "name": "",
  "signature": "sha256:a24b03be593fe029de07cbe676eec0c131a5a47ec9e3e44dda215118c0a0db2e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Multistep Methods\n",
      "\n",
      "Runge-Kutta type methods (which include Euler and modified Euler as special cases) are called single-step methods because they only use information from the last step computed. These methods are very useful when only initial conditions are available to start the solution; however after the solution has begun if we are savy enough to store a few previous values in memory, we can use interpolating polynomials to get better estimates of the function and derivative of the function over the step interval. This can prove useful\n",
      "\n",
      "The principle behind a multistep method is to utilize the past values of $y$ and/or $y'$ to construct a polynomial that approximates the derivative function, and extrapolate this into the next interval. Most methods use equispaced past values to make the construction of the polynomial easy. The Adams method is one of these methods. The number of past points that are used sets the degree of the polynomial and is therefore responsible for the truncation error. The order of the method is equal to the power of $h$ in the global error term of the formula, which is also equal to one more than the degree of the polynomial.\n",
      "\n",
      "To derive the relations for the Adams method, we write the differential equation $\\frac{dy}{dx} = f(x,y)$ in the form \n",
      "\n",
      "$$\n",
      "dy = f(x,y) dx\n",
      "$$\n",
      "\n",
      "and we integrate between $x_n$ and $x_n+1$:\n",
      "\n",
      "$$\n",
      "\\int_{x_n}^{x_{n+1}} dy = y_{n+1} - y_n = \\int_{x_n}^{x_{n+1}} f(x,y)dx\n",
      "$$\n",
      "\n",
      "In order to integrate the term on the right, we approximate $f(x,y)$ as a polynomail in $x$, driving this by making it fit at several past points. If we use three past points, the approximating polynomial will be quadratic. If we use four points, it will be cubic. Suppose we fit a second-degree Newton-Gregory backward polynomial:\n",
      "\n",
      "$$\n",
      "\\begin{matrix}\n",
      "\\int_{x_n}^{x_{n+1}} dy & = y_{n+1} - y_n = \\int_{x_n}^{x_{n+1}} \\left(f_n + s \\Delta f_{n-1} + \\frac{(s+1)s}{2} \\Delta ^2 f_{n-2} + error \\right) dx \\\\\n",
      " & = \\int_{s=0}^{s=1} \\left( f_n + s\\Delta f_{n-1} + \\frac{(s+1)s}{2} \\Delta^2 f_{n-2}\\right) h dx + \\int_{s=0}^{s=1} \\frac{s(s+1)(s+2)}{6} h^3 f'''(\\xi) hds\n",
      "\\end{matrix}\n",
      "$$\n",
      "\n",
      "Here we have changed the variable of integration to $s$ and identified $x_n$ as $x_0$. The interval of integration becomes $ s= 0$ to $s=1$. Performing the integration we get\n",
      "\n",
      "$$\n",
      "y_{n+1}-y_n = h \\left(f_n + \\frac{1}{2}\\Delta f_{n-1} + \\frac{5}{12} \\Delta^2 f_{n-2} \\right) + O(h^4)\n",
      "$$\n",
      "\n",
      "We could construct a difference table and use the previous equation as is, or we can further expand the differences of $f$ in terms of the values of $f_n, f_{n-1}, $ etc. Here we get a more useful formula:\n",
      "\n",
      "$$\n",
      "\\begin{matrix}\n",
      "y_{n+1} & = y_n + h \\left[ f_n + \\frac{f_n - f_{n-1}}{2} + \\frac{5(f_n 2f_{n-1} + f_{n-2})}{12} \\right] \\\\ \n",
      " & = y_n + \\frac{h}{24}(55 f_n - 59 f_{n-1} + 37 f_{n-2} - 9f_{n-3}) + O(h^5)\n",
      "\\end{matrix}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Milne's Method\n",
      "\n",
      "Milne's method is a multistep method that first predicts a $y_{n+1}$ by extrapolating values for the derivative. It differs from the Adam's method in that it integrates over more than one interval. The past values that we need may be computed by the R-K method, or possibly by the Taylor-Series method. In the Milne method we suppose that four equispaced starting values of $y$ are known, at the starting points $x_n, x_{n-1}, x_{n-2}$ and $x_{n-3}$. We can employ quadrature formulas to integrate as follows:\n",
      "\n",
      "$$\n",
      "\\frac{dy}{dx} = f(x,y)\\\\\n",
      "\\int_{x_{n-3}}^{x_{n+1}} \\left (\\frac{dy}{dx} \\right) dx = \\int_{x_{n-3}}^{x_{n+1}} f(x,y)dx = \\int_{x_{n-3}}^{x_{n+1}} P_2(x)dx\n",
      "$$\n",
      "\n",
      "where $P_2(x)$ is a quadratic interpolating polynomial. Omitting the details, we have:\n",
      "\n",
      "$$\n",
      "y_{n+1} - y_{n-3} = \\frac{4h}{3} (2f_n - f_{n-1} + 2f_{n-2}) + \\frac{28}{90} h^5 y^{(v)} (\\xi_1), x_{n-3} < \\xi_1 < x_{n+1}  (*)\n",
      "$$\n",
      "\n",
      "With this value of $y_{n+1}$ we can calculate $f_{n+1}$ reasonably well. In Milne's method, we use $(*)$ as a predictor formula and then correct with:\n",
      "\n",
      "$$\n",
      "\\int_{x_{n-1}}^{x_{n+1}} \\left(\\frac{dx}{dy}\\right) dx = \\int_{x_{n-1}}^{x_{n+1}}f(x,y)dx = \\int_{x_{n-1}}^{x_{n+1}} P_2 (x) dx, \\\\\n",
      "y_{n+1} - y_{n-1} = \\frac{h}{3} (f_{n+1} + 4f_n + f_{n-1}) - \\frac{h^5}{90} y^{(v)} (\\xi_2),  x_{n-1} < \\xi_2 < x_{n+1}  (**)\n",
      "$$\n",
      "\n",
      "In the predictor equation $(*)$ we extrapolate one panel to the right and left hence the larger error term. The corrector equation $(**)$ is not extrapolated and is the familiar $\\frac{1}{3}$ Simpson's quadrature rule.\n",
      "\n",
      "Milne's method is simple and has a nice error term, $O(h^5)$ for local error, but it is subject to an instability problem in certain cases. We will illustrate this instability below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Milne's Method Instability\n",
      "\n",
      "The instability in Milne's method shows up in certain cases in which the errors do not tend to zero as $h$ is made smaller. We will illustrate this instability with a simple example. Consider the differential equation $dy / dx = A y$, where $A$ is a constant. The general solution is $y = c e^{Ax}$. If $y(x_0) = y_0$ is the initial conidtion that the solution must satisfy then we have the analytic solution:\n",
      "\n",
      "$$\n",
      "y_n = y_0 e^{A(x_n-x_0)} (***)\n",
      "$$\n",
      "\n",
      "If we solve the differential equation with the Milne's method, we will have, from the corrector formula:\n",
      "\n",
      "$$\n",
      "y_{n+1} = y_{n-1} + \\frac{h}{3}(y'_{n+1} + 4y'_n + y'_{n-1})\n",
      "$$\n",
      "\n",
      "Letting $y'_n = Ay_n$, from the original differential equation, and rearranging we have:\n",
      "\n",
      "$$\n",
      "y_{n+1} = y_{n-1} + \\frac{h}{3}(Ay_{n+1} + 4Ay_n + Ay_{n-1})\\\\\n",
      "(1-\\frac{hA}{3})y_{n+1} - \\frac{4hA}{3}y_n - (1+\\frac{hA}{3})y_{n-1} = 0\n",
      "$$\n",
      "\n",
      "This is a second-order linear difference equation that can be solved in a manner analogoous to differential equations. The solution is \n",
      "\n",
      "$$\n",
      "y_n = C_1 Z_1^n + C_2 Z_2^n  (\\dagger)\n",
      "$$\n",
      "\n",
      "Where, $Z_1, Z_2$ are the roots of the quadratic\n",
      "\n",
      "$$\n",
      "(1-\\frac{hA}{3})Z^2 - \\frac{4hA}{3}Z - (1+\\frac{hA}{3}) = 0\n",
      "$$\n",
      "\n",
      "for simplification let $\\frac{hA}{3} = r$ the roots are then\n",
      "\n",
      "$$\n",
      "Z_{1,2} = \\frac{2r \\pm \\sqrt{3r^2 + 1}}{1-r}\n",
      "$$\n",
      "\n",
      "We want to compare $(\\dagger)$ to $(***)$ as the step size gets small. As $h \\rightarrow 0, r \\rightarrow 0, r^2 \\rightarrow 0$. We neglect the $3r^2$ term in comparison to the constant 1 under the radical it will be small, we have \n",
      "\n",
      "$$\n",
      "Z_1 = \\frac{2r+1}{1-r} = 1+3r+O(r^2) = 1+Ah + O(h^2)\\\\\n",
      "Z_2 = \\frac{2r-1}{1-r} =-1+r +O(r^2) =-(1-\\frac{Ah}{3})+O(h^2)\n",
      "$$\n",
      "\n",
      "Now let us comapre these results to a Maclaurin series expansion of the exponential functions, \n",
      "\n",
      "$$\n",
      "e^{hA} = 1+hA+O(h^2)\\\\\n",
      "e^{-hA/3} = 1-\\frac{hA}{3} + O(h^2)\n",
      "$$\n",
      "\n",
      "We can see that for $h\\rightarrow 0$\n",
      "\n",
      "$$\n",
      "Z_1 e^{-hA} \\hspace{10pt}\\&\\hspace{10pt}  Z_2 = e^{-hA/3}\n",
      "$$\n",
      "\n",
      "Hence the Milne solution is represented by \n",
      "\n",
      "$$\n",
      "y_n = C_1(e^{hA})^n + C_2(e^{-hA/3})^n = C_1 e^{A(x_n-x_0)} + C_2 e^{-A(x_n-X-0)/3}\n",
      "$$\n",
      "\n",
      "using the substitution $x_n-x_0 = nh$. The first term in this solution matches the analytic solution, but there is a *parasitic term* that is the second term. One can see that this term will decay away if $A$ is a positive number, but will grow exponentially if $A$ is negative. This behavior is independent of step size $h$, making $h$ smaller will have no benefit in eliminating the error."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Adams-Moulton Method\n",
      "\n",
      "A method that does not have the same instability problem as the Milne method, but is nearly as efficient, is the Adams-Moulton method. It also assumes a set of starting values already calculated by some other technique. Here we take a cubic polynomial through four-points, from $x_{n-3}$ to $x_n$, and integrate over one step, from $x_n$ to $x_{n+1}$. we have\n",
      "\n",
      "$$\n",
      "\\int_{x_n}^{x_{n+1}} (\\frac{dy}{dx})dx = \\int_{x_n}^{x_{n+1}}f(x,y)dx = \\int_{x_n}^{x_{n+1}}P_3(x)dx \\\\\n",
      "y_{n+1} - y_n = h\\left(f_n + \\frac{1}{2} \\Delta f_{n-1} + \\frac{5}{12} \\Delta ^2 f_{n-2} + \\frac{3}{8} \\Delta ^3 f_{n-3}\\right) + \\frac{251}{720} h^5 y^{(v)}(\\xi), \\hspace{5pt} x_{n-3} < \\xi < x_{n+1} (\\dagger \\dagger)\n",
      "$$\n",
      "\n",
      "In the Adams-Moulton method we use the $(\\dagger \\dagger)$ as a predictor equation and then continue by correcting $y_{n+1}$ before computing the next step. For the corrector formula we will approximate $f(x,y)$ as a cubic that fits over the interval $x_{n-2}$ to $x_{n+1}$ and integrate from $x_n$ to x_{n+1}$, we do not exptrapolate the polynomial and have a more favorable error term. The corrector formula is then\n",
      "\n",
      "$$\n",
      "y_{n+1} - y_n = h\\left(f_{n+1} - \\frac{1}{2} \\Delta f_n - \\frac{1}{12} \\Delta^2 f_{n-1} - \\frac{1}{24} \\Delta^3 f_{n-2} \\right) - \\frac{19}{720} h^5 y^{(v)} (\\xi_1), \\hspace{5pt} x_{n-2} < \\xi_1 < x_{n+1}\n",
      "$$\n",
      "\n",
      "The two equations above would require difference tables and are not well suited for computational programming. They are most commonly given in there equivalent form (which can be derived by a method of undetermined coefficients) as follows:\n",
      "\n",
      "Predictor: $y_{n+1} = y_n + \\frac{h}{24} (55 f_n - 59f_{n-1} + 37 f_{n-2} - 9f_{n-3})$\n",
      "\n",
      "Corrector: $y_{n+1} = y_n + \\frac{h}{24} (9 f_{n+1}+19f_n - 5f_{n-1} + f_{n-2})$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Psuedocode for Adams-Moulton method\n",
      "\n",
      "To approximate the solution of the initial value problem\n",
      "\n",
      "$$\n",
      "y' = f(x,y) a\\leq x \\leq b, y(a) = \\alpha,\n",
      "$$\n",
      "\n",
      "at $N+1$ equally spaced numbers in the interval $[a,b]$\n",
      "\n",
      "  1. Set $h = \\frac{(b-a)}{N}$\n",
      "  1. Set $x_0 = a$\n",
      "  1. Set $w_0 = \\alpha$\n",
      "  1. For $i = 1, 2, 3$ do Steps A-F (Compute starting values using R-K method)\n",
      "    1. Set $K_1 = hf(x_{i-1},w_{i-1})$\n",
      "    1. Set $K_2 = hf(x_{i-1} + \\frac{h}{2}, w_{i-1} + \\frac{K_1}{2})$\n",
      "    1. Set $K_3 = hf(x_{i-1} + \\frac{h}{2}, w_{i-1} + \\frac{K_2}{2})$\n",
      "    1. Set $K_4 = hf(x_{i-1} + h, w_{i-1} + K_3)$\n",
      "    1. Set $w_i = w_{i-1} + (K_1 + 2K_2 + 2K_3 + K_4)/6$\n",
      "    1. Set $x_i = a + ih$\n",
      "  1. For $i = 4, ..., N$ do Steps A-F\n",
      "    1. Set $x = a+ih$\n",
      "    1. Set $w = w_3 + h[55f(x_3, w_3) + 59f(x_2, w_2) + 37f(x_1,w_1) - 9f(x_0, w_0)]/24$ (Predict $w_i$)\n",
      "    1. Set $w = w_3 + h[9f(x,w) + 19f(x_3,w_3) - 5f(x_2,w_2) + f(x_1,w_1)]/24$ (Correct $w_i$)\n",
      "    1. For $j=0, 1, 2$ do Steps a-b\n",
      "      1. Set $x_j = x_{j+1}$\n",
      "      1. Set $w_j = w_{j+1}$\n",
      "    1. Set $x_3 = x$\n",
      "    1. Set $w_3 = w$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Convergence of Adams-Moulton method\n",
      "\n",
      "In all predictor-corrector schemes we have the option to recorrect the corrected estimate. We could do this multiple times until the difference of the corrected values is insignificant. In the Adams-Moulton method we usually do not recorrect, but instead use a value of $h$ that is small enough that a recorrection is unnecessary. We can develop a criterion for how small $h$ needs to be. Let us start by making some notational definitions:\n",
      "\n",
      "$\\hspace{1in}y_p$ = value of $y_{n+1}$ from predictor formula\n",
      "\n",
      "$\\hspace{1in}y_c$ = value of $y_{n+1}$ from corrector formula\n",
      "\n",
      "$\\hspace{1in}y_{cc}, y_{ccc}, etc. = $ values of $y_{n+1}$ if successie recorrections are made\n",
      "\n",
      "$\\hspace{1in}y_{\\infty} = $ value to which successive recorrections converge\n",
      "\n",
      "$\\hspace{1in} D = y_c - y_p$\n",
      "\n",
      "A change of $y_c$ by recorrecting would be\n",
      "\n",
      "$$\n",
      "y_{cc} - y_c = \\left(y_n + \\frac{h}{24}(9y'_c + 19y'_n - 5y'_{n-1} + y'_{n-2})\\right) - \\left(y_n + \\frac{h}{24}(9y'_p + 19y'_n - 5y'_{n-1} + y'_{n-2})\\right) = \\frac{19h}{24}(y'_c - y'_p)\n",
      "$$\n",
      "\n",
      "we can manipulate the difference $(y'_c -y'_p)$ as follows:\n",
      "\n",
      "$$\n",
      "y'_c -y'_p = f(x_{n+1}, y-c) - f(x_{n+1}, y_p) = \\frac{f(x_{n+1},y_c)-f(x_{n+1},y_p)}{y_c-y_p}(y_c-y_p) = f_y(\\xi_1)D, \\hspace{5pt} y_c < \\xi_1 < y_p\n",
      "$$\n",
      "\n",
      "Hence,\n",
      "\n",
      "$$\n",
      "y_{cc} - y_c = \\frac{9hD}{24}f_y(\\xi_1)\n",
      "$$\n",
      "\n",
      "If recorrected again, the result is\n",
      "\n",
      "$$\n",
      "y_{ccc} - y_{cc} = \\frac{9h}{24}(y'_{cc} - y'_c) = \\frac{9h}{24}f_y(\\xi_2)\\dot(y_{cc}-y_c)=\\frac{9h}{24}f_y(\\xi_2)\\left[\\frac{9hD}{24}f_y(\\xi_1)\\right] = \\left(\\frac{9hD}{24}\\right)^2[f_y(\\xi)]^2D, \\hspace{5pt} y_c < \\xi_2 < y_{cc}\n",
      "$$\n",
      "\n",
      "On further recorrections we will have a similar relation. We get $y_\\infty$ by adding all the correction of $y_p$ together:\n",
      "\n",
      "$$\n",
      "y_\\infty = y_p + (y_c - y_p) + (y_{cc} - y_c) + (y_{ccc} - y_c) + ... \\\\\n",
      "\\hspace{10pt} = y_p + D + \\frac{9hf_y(\\xi)}{24} D + \\left(\\frac{9hf_y(\\xi)}{24}\\right)^2D + \\left(\\frac{9hf_y(\\xi)}{24}\\right)^3D + ...\n",
      "$$\n",
      "\n",
      "This is a geometric series which only converges if the ratio is less than 1,\n",
      "\n",
      "$$\n",
      "y_\\infty = y_p + \\frac{D}{1-r}, \\hspace{10pt} r = \\frac{9hf_y(\\xi)}{24}, \\hspace{10pt} y_p < \\xi < y_\\infty\n",
      "$$\n",
      "\n",
      "Hence, unless the following is true,\n",
      "\n",
      "$$\n",
      "|r| = \\frac{h|f_y(\\xi)|}{\\frac{24}{9}} = \\frac{h|f_y(x_n,y_n)|}{\\frac{24}{9}} < 1\n",
      "$$\n",
      "\n",
      "The successive recorrections diverge. Our first convergence criterion is \n",
      "\n",
      "$$\n",
      "h < \\frac{\\frac{24}{9}}{|f_y(x_n,y_n)|}\n",
      "$$\n",
      "\n",
      "If we wish to have $y_c$ and $y_\\infty$ the same within one in the $N^{th}$ decimal place, then\n",
      "\n",
      "$$\n",
      "y_\\infty - y_c = \\left(y_p + \\frac{D}{1-r}\\right) - (y_p + D) = \\frac{rD}{1-r} < 10^{-N}\n",
      "$$\n",
      "\n",
      "If $r << 1$, the fraction\n",
      "\n",
      "$$\n",
      "\\frac{r}{1-r} = r\n",
      "$$\n",
      "\n",
      "and a second convergence criterion, which ensures that the first corrected value is adequate is \n",
      "\n",
      "$$\n",
      "D \\dot 10^N < |\\frac{1}{r}| = \\frac{\\frac{24}{9}}{h|f_y(x_n,y_n)|} \n",
      "$$\n",
      "\n",
      "The accuracy criterion is \n",
      "\n",
      "$$\n",
      "D\\dot 10^N < 14.2\n",
      "$$\n",
      "\n",
      "The criterion are valid for a single first order equation only. A similar analysis for a system can be done but is much more complicated."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}