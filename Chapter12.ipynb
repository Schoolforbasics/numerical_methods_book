{
 "metadata": {
  "name": "",
  "signature": "sha256:e2a8d1f9dd629d48cee283caca76a7d8d1f164f47f22f0a8f086bb44872f1c6b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Numerical Integration (Quadrature)\n",
      "\n",
      "One strategy in developing formulas for numerical integration is similar to that for numerical differentiation. We fit a polynomial appxoimation through points of the function and then integrate this polynomial approximation to the function. If the points are equispaced then the familiar Newton-Gregory forward polynomial is a convenient place to start\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\int_a^b f(x)dx = \\int_a^bP_n(x_s)dx$\n",
      "\n",
      "Of course, the results will not be exact because the polynomial is not idential to $f(x)$. Therefore, we have an error expression of the form:\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Error$ = \\int_a^b \\begin{pmatrix}s\\\\n+1\\end{pmatrix} h^{n+1}f^{(n+1)}(\\xi)dx$\n",
      "\n",
      "If the interval of integration $(a,b)$ matches the range of fit of the polynomial, $(x_0, x_n)$ we get what are called the Newton-Cotes formulas, a set of integration rules corresponding to the varying degrees of the interpolation polynomial. The first three, should look very familiar shortly.\n",
      "\n",
      "The utility of numerical integration extends beyond the need to integrate a function known only as tabular data. Many times, either because we are lazy, the problem is too difficult, or the function simply has not closed form solution we use numerical integration to approximate the integral of analytic functions as well. The process of numerical integration is often called quadrature."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Newton-Cotes Formulas\n",
      "\n",
      "Let us develop three important Newton-Cotes formulas. During the integration, we will need to change the variable of integration from $x$ to $s$ since our polynomials were expressed in terms of $s$. Observe that $dx = h ds$. \n",
      "\n",
      "For $n = 1$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\int_{x_0}^{x_1} f(x)dx = \\int_{x_0}^{x_1} (f_0+s\\Delta f_0)dx = h \\int_{s=0}^{s=1} (f_0 + s\\Delta f_0) ds$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ = h f_0s]_0^1 + h\\Delta f_0 \\frac{s^2}{2} ]_0^1 = h(f_0 + \\frac{1}{2}\\Delta f_0)$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ = \\frac{h}{2} [2f_0 + (f_1 - f_0)] = \\frac{h}{2}(f_0+f_1)$\n",
      "\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Error $=\\int_{x_0}^{x_1} \\frac{s(s-1)}{2}h^2 f''(\\xi) dx = h^3 f''(\\xi_1) \\int_0^1 \\frac{s^2-s}{2} ds$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ = h^3 f''(\\xi_1)\\left(\\frac{s^3}{6}-\\frac{s^2}{4}\\right)]_0^1 = -\\frac{1}{12} h^3 f''(\\xi_1)$,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ x_0\\leq \\xi_1 \\leq x_1$\n",
      "\n",
      "\n",
      "For $n=2$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\int_{x_0}^{x_2} f(x)dx = \\int_{x_0}^{x_2} (f_0 + s\\Delta f_0 + \\frac{s(s-1)}{2} \\Delta^2 f_0)dx$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ = h \\int_0^2(f_0 + s\\Delta f_0 + \\frac{s(s-1)}{2} \\Delta^2 f_0)ds$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ = h f_0 s]_0^2 + h\\Delta f_0 \\frac{s^2}{2}]_0^2 + h\\Delta^2 f_0(\\frac{s^3}{6} - \\frac{s^2}{4})]_0^2$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ = h(2f_0 + 2\\Delta f_0 + \\frac{1}{3} \\Delta^2 f_0) = \\frac{h}{3}(f_0 + 4f_1 + f_2)$\n",
      "\n",
      "Omitting the details of the integration we find the error to be \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Error $=- \\frac{1}{90} h^5 f''''(\\xi_1)$, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_0 \\leq \\xi_1 \\leq x_2$\n",
      "\n",
      "And finally for $n=3$, omitting details we have \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\int_{x_0}^{x_3} f(x) dx = \\int_{x_0}^{x_3}P_3 (x_s) dx = \\frac{3h}{8}(f_0 + 3f_1 + 3f_2 + f_3)$\n",
      "\n",
      "and\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Error $= - \\frac{3}{80} h^5 f''''(\\xi_1)$, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $x_0 \\leq \\xi_1 \\leq x_3$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Summary of Newton-Cotes formulas\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ \\int_{x_0}^{x_1} f(x) dx = \\frac{h}{2} (f_0 + f_1) - \\frac{1}{12} h^3 f''(\\xi)$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ \\int_{x_0}^{x_2} f(x) dx = \\frac{h}{3} (f_0 + 4f_1 + f_2) - \\frac{1}{90} h^5 f''''(\\xi)$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $ \\int_{x_0}^{x_3} f(x) dx = \\frac{3h}{8}(f_0 + 3f_1 + 3f_2 + f_3) - \\frac{3}{80}h^5 f''''(\\xi)$\n",
      "\n",
      "Notice that for both $n=2$ and $n=3$ the error terms are $O(h^5)$. This means that the error of integration using a quadratic is similar to the integral using a cubic. Also notice that the quadratic's coefficient $(-\\frac{1}{90})$ is smaller than the coefficient for the cubic $(-\\frac{3}{80})$. The formula based on the quadratic is unexpectedly accurate. This phenomenon is true of all the even-order Newton-Cotes formulas; each has an order of $h$ in its error termt hat is the same as the formula for the next heighest order. This suggests that the even-order rules are especially useful."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Trapezoid Rule\n",
      "\n",
      "The first Newton-Cotes formula, based on approximating $f(x)$ on $(x_0, x_1)$ by a straight line, is called the trapezoid rule."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wish to apply the forumla for an extended region (more than one interval) of equispaced poitns we have\n",
      "\n",
      "$$ \\int_{x_i}^{x_{i+1}} f(x) dx = \\frac{f(x_i)+f(x_{i+1})}{2}(\\Delta x) = \\frac{h}{2}(f_i + f_{i+1})$$\n",
      "\n",
      "For $(a,b)$ subdivided into sub intervals of size $h$.\n",
      "\n",
      "$$\\int_a^b f(x)dx = \\sum_{i=1}^n \\frac{h}{2}(f_i + f_{i+1}) = \\frac{h}{2}(f_1 + f_2 + f_2 + f_3 + f_3 + ... + f_n + f_{n+1})\\\\\n",
      "\\int_a^b f(x) dx = \\frac{h}{2}(f_1 + 2f_2 + ... + 2f_n + f_{n+1})$$\n",
      "\n",
      "This is known as *extended trapezoid rule.* Recalling from the error of Newton-Cotes formula we have the local error (the error for a single step) for trapezoid rule as\n",
      "\n",
      "$$ Local Error = -\\frac{1}{12} h^3 f''(\\xi_1), x_0 \\leq \\xi_1 \\leq x_1$$\n",
      "\n",
      "But we normally apply the trapezoid rule to a series of sub intervals, so the global error would be something like\n",
      "\n",
      "$$Global Error = -\\frac{1}{12} h^3 [f''(\\xi_1) + f''(\\xi_2) + ... + f''(\\xi_n)]$$\n",
      "\n",
      "If we assume that $f''(x)$ is continuous on $(a,b)$, there is some value of $x$ in $(a,b)$, say $x = \\xi$ at which the value of $[f''(\\xi_1) + f''(\\xi_2) + ... + f''(\\xi_n)] = nf''(\\xi)$. Then since $n h = b-a$ we have\n",
      "\n",
      "$$Global Error = -\\frac{1}{12} h^3 f''(\\xi) = -\\frac{(b-a)}{12}h^2 nf''(\\xi) = O(h^2)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Simpson's Rules\n",
      "\n",
      "The Newton-Cotes formulas based on quadratic and cubic polynomails are widely used. They are typically known as Simpson's rules. The second-degree Newton-Cotes formula integrates a quadratic over $2\\Delta x$ intervals that are of uniform width. Repeating from earlier:\n",
      "\n",
      "$$ \\int_{x_0}^{x_2} f(x)dx = \\frac{h}{3}(f_0 + 4f_1 + f_2) - \\frac{h^5}{90}f''''(\\xi), x_0 \\leq \\xi \\leq x_2$$\n",
      "\n",
      "This is the popular Simpson's $\\frac{1}{3}$ rule, which has a local error of $O(h^5)$. If we apply this to a succession of pairs of intervals to evaluate $\\int_a^b f(x)dx$, we get\n",
      "\n",
      "$$\\int_a^b f(x) dx = \\frac{h}{3}(f_1 + 4f_2 + 2f_3 + 4f_4 + 2f_5 + ... + 2f_{n-1} + 4f_n + f_{n+1})-\\frac{(b-a)}{180} h^4 f''''(\\xi), x_1 \\leq \\xi \\leq x_{n+1} $$\n",
      "\n",
      "Below is a plot which illustrates the idea of Simpson's $\\frac{1}{3}$rule. Since we integrate over two intervals each time, we require that the data is subdivided into an even number of intervals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The third Newton-Cotes formula that finds frequent use is obtained by integrating a cubic interpolation polynomial over its range of fir. The local rule (from the previous section) is:\n",
      "\n",
      "$$\\int_{x_0}^{x_3} f(x) dx = \\frac{3h}{8}(f_0 + 3f_1 + 3f_2 + f_3) - \\frac{3}{80}h^5f''''(\\xi), x_0 \\leq \\xi \\leq x_3$$\n",
      "\n",
      "This is Simpson's $\\frac{3}{8}$ rule, which has a local error of $O(h^5)$. If we apply this to a succession of triplicates of intervals to evaluate $\\int_a^b f(x) dx$, we get\n",
      "\n",
      "$$\\int_a^b f(x) dx = \\frac{3h}{8}(f_1 + 3f_2 + 3f_3 + 2f_4 + 3f_5 + 3f_6 + ... + 2f_{n-2} +3f_{n-1} + 3f_n + f_{n+1}) - \\frac{(b-a)}{80}h^4 f''''(\\xi), x_1 \\leq \\xi \\leq x_{n+1}$$\n",
      "\n",
      "Below is a plot which illustrates the idea of Simpson's $\\frac{3}{8}$ rule. Since we integrate over three intervals each time, we require that the data is subdivided into a number of intervals divisible by three. But, as we have seen, the order of the global error for both of Simpson's rules is $O(h^4)$ and the coefficient for the $\\frac{3}{8}$ rule is larger. One might wonder why we would ever use the $\\frac{3}{8}$ rule, and this is a valid observation. In pratice it is often not true that tabulated data is divisible by 2. In these cases we typically combine the two methods, applying Simpson's $\\frac{1}{3}$ rule to all the data except for the last three intervals in which we pick up with the Simpson's $\\frac{3}{8}$ rule."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Psuedocode for Simpson's Rule\n",
      "\n",
      "The following pseudocode is used to approximate the integral $I = \\int_a^b f(x)dx$ using Simpson's $\\frac{1}{3}$ rule. The same approach can be used with minor modifications for Trapezoid rule and Simpson's $\\frac{3}{8}$ rule.\n",
      "\n",
      "  1. Set $h=(b-a)/n$ where $n$ is the number of intervals int eh larger interval $(a,b)$\n",
      "  1. Set $XI0 = f(a) + f(b)$\n",
      "  1. Set $XI1 = 0$\n",
      "  1. Set $XI2 = 0$\n",
      "  1. For $i = 1, ..., n-1$ do Steps A-C\n",
      "    1. Set $X = a + i h$\n",
      "    1. If $i$ is even do Step a, if not do Step b\n",
      "      1. Set $XI2 = XI2 + f(X)$\n",
      "      1. Set $XI1 = XI1 + f(X)$\n",
      "    1. Set $XI = h(XI0 + 2XI2 + 4XI1)/3$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Other ways of deriving intergration formulas\n",
      "\n",
      "We can use the symbolic tools we developed for deriving differentiation formulas in the last lecture in the exact same way for integration formulas.  This is a somewhat straightforward procedure, therefore it will be omitted here in favor of another technique.  This method may be called the *method of undetermined coefficients*. We express the formula as a sum of $n+1$ terms with unknown coefficients, and then evaluate the coefficients by requiring that the formula be exact for all polynomails of the degree $n$ or less. Let's look at an example where we express the integral as a weighted sum of three equispaced function values over the limits of integration.\n",
      "\n",
      "$$\\int_{-1}^{1} f(x)dx = af(-1)+bf(0)+cf(1)$$\n",
      "\n",
      "Since the formula contains three terms, we can require it to be correct for all polynomails of degree 2 or less. This process is illustrated below:\n",
      "\n",
      "$$\n",
      "f(x) = 1; \\int_{-1}^1 1dx = 2 = a(1) + b(1) + c(1) = a+b+c\\\\\n",
      "f(x) = x; \\int_{-1}^1 xdx = 0 = a(-1)+ b(0) + c(1) = -a+c\\\\\n",
      "f(x) = x^2;\\int_{-1}^1x^2dx=\\frac{2}{3}=a(1)+b(0)+c(1)=a+c\n",
      "$$\n",
      "\n",
      "Solving these three equations simultaneously gives $a = \\frac{2}{3}, b = \\frac{4}{3}, c = \\frac{1}{3}$. Here the spacing was 1, but the integral will be proportional to $\\Delta x = h$. We then get Simpson's $\\frac{1}{3} rule:\n",
      "\n",
      "$$\\int_{-h}^h f(x) dx = h[\\frac{1}{3}f(-h) + \\frac{4}{3}f(0) + \\frac{1}{3}f(h)]$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Gaussian Quadrature\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}